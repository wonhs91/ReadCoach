{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ea4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_id     score                            title    author_name  \\\n",
      "0  w_02204  7.428220         Kynthos: Legacy (Book 2)      Sam Smith   \n",
      "1  w_01058  7.078107  The Prophecy of Solara (Book 1)    Riley Brown   \n",
      "2  w_00422  6.510206                     Mythos: Code    Logan White   \n",
      "3  w_01152  5.913240           Golden Garden (Book 1)    Riley Allen   \n",
      "4  w_00753  5.722825         Eldoria: Throne (Book 3)   Skyler Jones   \n",
      "5  w_02997  5.281706   The Secret of Kynthos (Book 1)  Sage Anderson   \n",
      "6  w_02527  4.821906   The Legacy of Nemoris (Book 2)      Sam Allen   \n",
      "7  w_01916  4.379576            Autumn Crown (Book 2)   Morgan Allen   \n",
      "8  w_01814  4.326840            The Phoenix of Avalon   Alex Johnson   \n",
      "9  w_00125  3.848648   The Garden of Eldoria (Book 3)    Reese Perez   \n",
      "\n",
      "             genre  \n",
      "0        Biography  \n",
      "1          Fantasy  \n",
      "2           Horror  \n",
      "3        Biography  \n",
      "4         Children  \n",
      "5          Fantasy  \n",
      "6        Self-Help  \n",
      "7           Horror  \n",
      "8  Science Fiction  \n",
      "9         Children  \n"
     ]
    }
   ],
   "source": [
    "# Quickstart: Item–Item kNN on this data\n",
    "import pandas as pd, numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ---------- Load ----------\n",
    "train = pd.read_csv(\"res/interactions_train.csv\", parse_dates=[\"ts\"])\n",
    "books = pd.read_csv(\"res/books.csv\")\n",
    "\n",
    "# collapse to canonical work_id (so editions don't fragment signal)\n",
    "train = train[[\"user_id\",\"work_id\",\"weight\"]].dropna()\n",
    "train[\"weight\"] = train[\"weight\"].astype(np.float32)\n",
    "\n",
    "# ---------- Encode ids ----------\n",
    "u2i = {u:i for i,u in enumerate(train[\"user_id\"].unique())}\n",
    "w2i = {w:i for i,w in enumerate(train[\"work_id\"].unique())}\n",
    "i2w = {i:w for w,i in w2i.items()}\n",
    "\n",
    "train[\"_uid\"] = train[\"user_id\"].map(u2i)\n",
    "train[\"_iid\"] = train[\"work_id\"].map(w2i)\n",
    "\n",
    "# ---------- Build user–item matrix with weights ----------\n",
    "n_users = train[\"_uid\"].max()+1\n",
    "n_items = train[\"_iid\"].max()+1\n",
    "R = csr_matrix((train[\"weight\"].values,\n",
    "                (train[\"_uid\"].values, train[\"_iid\"].values)),\n",
    "               shape=(n_users, n_items))\n",
    "\n",
    "# ---------- Fit item–item kNN (cosine) ----------\n",
    "item_user = R.T.tocsr()\n",
    "knn = NearestNeighbors(n_neighbors=101, metric=\"cosine\", algorithm=\"brute\", n_jobs=-1)  # 100 neighbors + self\n",
    "knn.fit(item_user)\n",
    "\n",
    "# ---------- Recommend for a user ----------\n",
    "def recommend_for_user(user_id, topn=10):\n",
    "    u = u2i.get(user_id)\n",
    "    if u is None: return []\n",
    "    seen_items = set(R.getrow(u).indices.tolist())\n",
    "    scores = {}\n",
    "    for iid in seen_items:\n",
    "        dists, nbrs = knn.kneighbors(item_user[iid], return_distance=True)\n",
    "        dists, nbrs = dists[0], nbrs[0]\n",
    "        for dist, nb in zip(dists[1:], nbrs[1:]):  # skip self\n",
    "            sim = 1.0 - float(dist)\n",
    "            if nb not in seen_items:\n",
    "                scores[nb] = scores.get(nb, 0.0) + sim\n",
    "    top = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:topn]\n",
    "    return [(i2w[i], s) for i, s in top]\n",
    "\n",
    "# Example user → titles\n",
    "books_by_work = books.drop_duplicates(\"work_id\")[[\"work_id\",\"title\",\"author_name\",\"genre\"]]\n",
    "test = pd.read_csv(\"res/interactions_test.csv\", parse_dates=[\"ts\"])\n",
    "example_user = test.sample(1, random_state=0)[\"user_id\"].iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15544f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = recommend_for_user(example_user, topn=10)\n",
    "out = pd.DataFrame(recs, columns=[\"work_id\",\"score\"]).merge(books_by_work, on=\"work_id\", how=\"left\")\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
